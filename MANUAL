A brief description of each of the macros, input file
names, and how they interact



After using 'make' to compile CoBaLEP.cc into an executable, we can
begin the simulation phase. The executable requires two inputs: a
macro, and a number. The macro should handle primary particle
generation, and the input number will act as the seed for the
simulation's random number generator. An example set of commands to
make this happen would be:

1a. >) make
2a. >) ./CoBaLEP mac/muons.mac 309841 //user defined input seed

muons.mac generates high energy but monoenergetic muons, and Co60.mac
generates stationary Cobalt 60 nuclei. weighted.mac (the recommended
macro for execution at this time) samples a file of 90,000 muons
simulated by Ralph Massarczyk from ground level to the 4850 level at
SURF. This file is also in the mac/ directory for ease of access and
is titled SmallMuonFile. For more information, check out the macros
yourself. To better understand what's in the simulation, you can read
the .cc file.


I made a script, runsims.sh, to use the slurm environment's batch
submission protocols for running multiple simulations at a time. This
script also randomizes the input number for the simulation. If your
institution uses a different job submission protocol, you'll have to
create your own script, keeping in mind that the script should feed a
macro name and a random number into the CoBaLEP executable as
indicated on step 2a up above. I also made a quick root script, called
jobsubmit, which will use the runsims.sh slurm script to submit 100
simulations jobs at a time through USD HPC. So in reality, my first few
commands are:

1b. >)make
(switch to production directory)
2b. >)sbatch runsims.sh //single job, random input seed

OR

1c. >)make
2c. >)root -x jobsubmit.C //Recommended, 100 jobs & 100 random input seeds

This will get 100 batches of 100 muons each (10,000 total) to start
simulating using the weighted.mac parameters. Pretty simple, huh?


After the main CoBaLEP executable is ran, it should output a .root
file with the name 'output#####.root', where the #s are equal to the
input seed. This is where the so called 'processing' phase begins. At
present the processing involves 3 steps: hit building, event building,
and optionally, chaining together of all summed files.


The hitbuilder.C script automatically finds all output#####.root
files in the current directory and builds 'hits' out of
them. Currently, hits are defined as all of the energy depositions
from the simulation file that occur in the same active volume
(i.e. the same detector) within a 20us time window. It's important to
note the hit builder also processes each muon individually, so no
hit has depositions from two separate muons. I've thoroughly
documented how hitbuilder.C works in the program itself, so check
that out if you'd like. The output files from the hit builder are
named bundledoutput####.root, where the number in the filename is the
same as the simulation file it was built from. The bundledoutput files
have a messy internal structure, but this is tolerable for now because
their only current use is as input for the next step in the processing
phase: event building.

3a. >)root -x hitbuilder.C //No longer works

VERY IMPORTANT UPDATE: hit building usually takes about 5 minutes
for a single simulation file, but can overflow a node's memory.
As such, it's not advisable to process all files in the current
directory at one time. As you may recall, simulation files are all
tagged with a unique number in their name, e.g. output#####.root. To
work around the processing time issue, I now require hitbuilder.C
to take a numerical input. Then, only simulation files whose unique
number begins with the same digits as the input number will be
processed.

If this is confusing here's an example. I run root -x
hitbuilder.C(544), so 544 is the numerical input. Now, if a
simulation file is named output544.root, it will be processed. BUT it
will also be processed if it's named output5448189.root, or
output544603.root, etc, so long as the first three numbers in its
unique ID match the numerical input. output1654436.root would not be
processed, because while it does contain '544' in its unique ID, it is
not the first sequence of digits.

3b. >)root -x hitbuilder.C(anynumber) //Recommend anynumber be 2 digits

I made another batch submission script, runbuilder.sh, and another
accompanying root file to submit it many times, manysubmit.C. I would
highly recommend using these to do any hit building, or to build
your own batch submission script. manysubmit.C submits every possible
combination of starting digits for the simulation files' unique IDs,
so every file gets processed, but now the labor is split across many
machines.

3c. >) root -x manysubmit.C //Highly recommended over 3b.


The event building  program is called eventbuilder.C It takes
the hitbuilder.C output as its input. This somewhat simpler
program builds events as per the MAJORANA definition, and calculates hit
energy (per detector, which can then be added) and multiplicity for
each event. The output of eventbuilder.C is labeled sumtree#####.C, where
again the number carries over from the original simulation file's
unique ID. eventbuilder.C takes very little time to process any number of
files.


As a final step, to make high statistics analysis easier, the user may
use the program chainingtwo.C. This simply uses a TChain to merge all
sumtree files into a single file, which is then titled allsums.root.
Simple analysis can then be done easily on allsums.root. For details on
parameter names for analysis, please read eventbuilder.C's source code.
chainingone.C chains unprocessed files e.g. raw simulation data.



Below are exactly the commands I would run to complete the simulations
and processing from start to finish for 10,000 muons. First, you
will need a directory with the above scripts. I've listed the
path below this paragraph in step 0. This folder is called scripts.

Another folder, mac, contains the file used (for now) to sample the
angular distribution of the muons, as well as some other analysis
scripts which are either deprecated or for specific uses only.


//All commands assume you are located in the directory containing
//CoBaLEP.cc

//Use cmake (if necessary) and make

//Copy the scripts folder and rename it

1. >)cp -f scripts /wherever/you/want/

//This should be the directory from which you run steps 2. to 5.


The following locations have file paths that will need to be changed
to reflect your setup:

src/ShowerGenerator.cc has a path you can find by searching for
'$WORKINGDIR' in a text editor. You will need to change this to point
to your own 'mac' directory. You can also set up your own $WORKINGDIR
environment variable to point to the directory containing CoBaLEP.cc

The very last line of scripts/runsims.sh needs to be changed
twice: the first path should point to the directory your CoBaLEP
executable is in. The second path should point to your 'mac' folder.


//Change to the renamed instance of the scripts directory

2. >)root -x jobsubmit.C //takes 100 seconds to run

//Dependencies of step 2: runsims.sh,
//CoBaLEP (the executable), weighted.mac


Simulations can take up to 24 hours, depending on whether or not the
rock has been removed from the simulation geometry. This is an
advanced setting and beyond the scope of this manual. By default the
rock is included.


//After all simulations finish in 24 or so hours...
//3a is optional, but moves all the slurm output files to one new file
3a. >)chainingone.C
3b. >)root -x manysubmit.C //takes 100 seconds to run

//Dependencies of step 3: runbuilder.sh, hitbuilder.C,
//simulation output files


Hit building can also take a while. If you're ever worried
it's taking too long or stuck processing, try reading any of
the slurm output logs being created in real time.
emacs -nw slurm-#####.out //(##### is jobID of the slurm job)
This should show some numbers tracking the progress of the hit
builder. Read the source file if you wanna know what these numbers
are. All you need to know right now is that if you run the same
command a few minutes later and the numbers have changed at all,
the hit builder is still advancing.


//Once all the hits are built...

4. >)root -x eventbuilder.C

//Dependencies of step 4: having hit builder output files
//eventbuilder.C automatically cleans up the slurm files
//into one big file, whether or not you did it before
//so it's recommended to do it before as well, in 3a


(no longer true but kept in case the problem returns)
In my experience, 1-2% of hit builder output files are corrupted.
This will be VERY obvious when you try to run eventbuilder.C on
them. Luckily, I set up eventbuilder.C to output the name of each file
it's about to try to process, so if you suddenly get a huge number of
errors on your terminal just scroll up until you find the name of the
last file that the event builder tried to process. Then, you can move
or delete this corrupted hit file, delete any output files from the
event builder, and simply run it again. This solution is not very
elegant... but it works for now.


5. (optional) >)root -x chainingtwo.C

//Dependencies of step 5: having event builder output files
//After this, production should be all done!



There is one other set of three analysis scripts in scripts/ worth
mentioning. The "tracing back" scripts, consisting of traceback.C,
tracetwo.C, and finaltrace.C, serve a single purpose.

In analysis, it sometimes chances that information contained in the
fully processed 'event-built' file warrants a closer look at the raw
simulation data from whence it came. However, there's a reason the
hitbuilder and eventbuilder scripts are necessary - the raw and final
event data are incompatible, for reasons beyond the scope of this
manual. I'd encourage those interested to look up my talk at the
October 2018 DNP/JPS meeting. Anyway, the tracing back scripts allow
a user to specify some cuts on the fully built data using traceback.C
and then call trace2.C and finaltrace.C in order to retrieve the raw
data associated with those cuts. There will be a new ROOT file called
cutsoutput.root containing the raw data associated with the cut(s)
made in traceback.C's runtime. This is a pretty advanced script, so
it may be that I'm the only one who ends up using it anyway.



Below are the names and functions of the other programs appearing in
the mac directory. Many of these are either old and nonfunctional,
specialized, or both, so it's unlikely anybody else reading this will
ever have to use them. Even so, extra documentation doesn't hurt.


accessralphmuonfile.C - Pretty descriptive. Just a specialized program
I made to access the large file of simulated muons Ralph gave me,
arrange the parameters in a way that Geant4 likes, and then output
them to a smaller version of Ralph's muon file, which I named
SmallMuonFile.root. Currently this script is messed up because I was
using it to do some testing. I can fix it easily... if I want to.
I kind of like having it messed up because that way I can't accident-
ally override the SmallMuonFile.root with something else.

angulardistributionsofsmallmuonfile.C - The name speaks for itself.
Accesses SmallMuonFile.root, calculates angular distributions of
the muons, and plots them. You won't get what you want unless you
mess with the script, though, so this one's also a little busted.

Co60.mac - As explained elsewhere, use this instead of
'weighted.mac' if you wanna simulate Co60 decays instead of muons.

CoBaLEP_neutrons.cc - An alternative version of CoBaLEP.cc
Used for simulations I did of a muon through solid rock, in which
I studied the neutron production. May use again one day, who knows.

CoBaLEP_original.cc - An alternative version of CoBaLEP.cc
A snapshot of the cc file at the time CoBaLEP_neutrons.cc was made.

findAmanually.C - A test file when implementing the Mei Hime
energy weighting functionality (see changelog for details).
Was used to determine there was a problem with the energy
distribution in the original SmallMuonFile, and subsequently
necessitated the switch to weighting vie branch.

fittingnewmuonfile.C - A test file when implementing the Mei Hime
energy weighting functionality (see changelog for details).

heatmap.C - Old analysis program I used to use to plot the starting
z position of shower secondaries that hit the detectors versus the
name of the process which created them. These plots were pretty and
informative (pretty informative), so I just might reimplement this
at some point during the analysis phase.

muons.mac - A muon sample which uses GEANT4's General Particle
Source. weighted.mac samples from a file/

neutronsforGe.mac - Macro for sampling neutrons instead of muons.
Used in a study of neutrons impinging on Ge that I did to satisfy
the curiosity of some colleagues.

neutronMultiplicitySource.mac - Muon sampling macro used in the
neutron production in rock study mentioned in CoBaLEP_neutrons.cc.

nucleardelayinfo.C - Another fledgling analysis program, designed
to record information about particles produced from delayed nuclear
decays which find their way to a sensitive detector mass.
This has since been incorporated into the main program in a much
more sophisticated way.

specificcreatorprocess.C - An analysis program which allows me to
search for specific creator processes in the simulation outputs. In
its early stages as well, but at least functional. Probably not
necessary now that I know more than one thing about using TCut.

validationforangularcut.C - A trigonometric cut was implemented in
the ShowerGenerator.cc file, to prevent simulation of muons that
never even come within 5m of the detector shielding. This saves a
lot of runtime. This script was used to validate it, but needs to
be updated and run again for many reasons.

weighted.mac - As mentioned before, the 'standard' sampling macro
for production. At this point, the only thing it samples from
the SmallMuonFile is angular distribution at SURF.